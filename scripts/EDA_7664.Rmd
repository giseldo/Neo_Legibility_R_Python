---
title: "Análise Exploratório Projeto 7764"
output: html_notebook
author: 'Giseldo da Silva Néo'
---

```{python}
import pandas as pd
import matplotlib.pyplot as plt
from textblob import TextBlob
import textstat
from sklearn.svm import SVR
from sklearn.feature_extraction.text import TfidfVectorizer
```

```{python}
import logging; 
logging.getLogger().setLevel(logging.CRITICAL)
```

```{python}
name = '7764'
filename = '../data/{}.csv'.format(name)
df = pd.read_csv(filename)
df.head()
```

```{python}
df.shape
```
Este conjunto de dados tem 355 observações. Cada observação é uma User Story do Projeto 7764. O conjunto de dados tem 5 colunas.

```{python echo=False}
df["context"] = df["title"] + df["description"]
df = df.drop(['created', 'issuekey', 'title', 'description'], axis=1)
df['context'] = df['context'].astype(str)
df.head()
```

```{python}
value_count = df['storypoints'].value_counts().sort_index()
df_value_count = pd.DataFrame(data = {'valures': value_count.index, 'Contagem': value_count.values})
df_value_count
```


```{python}
df['storypoints'].describe()
```
A grande maioria das User Story. 75% da amostra foi medido como 1, 2 ou 3 Story Points.


```{python}
plt.figure(figsize=(8, 6))
value_count.plot(kind='bar')
plt.title('Value Counts dos Story Points do Projeto 7764')
plt.xlabel('Valores do Story Point')
plt.ylabel('Contagem de vezes dos Story Points')
plt.show()
```

```{python}
plt.figure(figsize=(8, 2))
plt.boxplot(df['storypoints'], vert=False)
plt.title('Boxplot da Coluna Story Point')
plt.xlabel('Valores do Story Point')
plt.show()
```

Existem outliers nos Story Points, ou seja alguns Story Points são distantes da média mais do que 2 desvios padrão.


```{python}
mean = df['storypoints'].mean()
std_dev = df['storypoints'].std()
outlier_cutoff = 2 * std_dev
df_clean = df[(df['storypoints'] >= mean - outlier_cutoff) & (df['storypoints'] <= mean + outlier_cutoff)]
df_clean.head()
```

```{python}
plt.figure(figsize=(8,2))
plt.boxplot(df_clean['storypoints'], vert=False)
plt.title('Boxplot dos Story Points do Projeto 7764 depois da remoção dos outliers')
plt.show()
```

```{python}
value_count = df_clean['storypoints'].value_counts().sort_index()
plt.figure(figsize=(8, 6))
value_count.plot(kind='bar')
plt.title('Value Counts dos Story Points do Projeto 7764')
plt.xlabel('Valores do Story Point')
plt.ylabel('Contagem de vezes dos Story Points')
plt.show()
```

```{python}
# separação treino e teste
num_linhas_treino = int(len(df_clean) * 0.7)
dados_treino = df_clean.iloc[:num_linhas_treino]
dados_teste = df_clean.iloc[num_linhas_treino:]
```

```{python}
media_sp = dados_treino['storypoints'].mean()
media_sp
```

A média de Story Point de todo o conjunto de dados é de 2.15 Story Point

```{python}
def mean_absolute_error(y_true, y_pred):
  """
  Calcula o Mean Absolute Error (MAE), entre os valores verdadeiros (y_true) e os valores previstos (y_pred)

  Args:
    y_true: Uma lista ou array Numpy dos valores verdadeiros.
    y_pred: Uma lista ou array NumPy dos valores previstos.

  Returns:
    mae: O Mean Absolute Error entre y_true e y_pred
  """
  if len(y_true) != len(y_pred):
    raise ValueError('Os tamanhos de y_true e y_pred devem ser iguais')
  absolute_Errors =[abs(true-pred) for true, pred in zip(y_true, y_pred)]
  mae = sum(absolute_Errors) / len(y_true)
  return mae
```


```{python}
lista_y_pred = [media_sp] * len(dados_teste)
mae_media_sp = mean_absolute_error(dados_teste['storypoints'], lista_y_pred)
mae_media_sp
```

o MAE é de 1.31, quando utilizamos a média dos Story Points. Ou seja, o Erro médo absoluto é de 1.28 SP quando sempre utilizamos um valor fixo, lembrando que foi utilizado todo o conjunto de dados. 

```{python}
df_results = pd.DataFrame(data=[['Media', mae_media_sp, 'blue']], columns=['modelo', 'MAE Teste', "color"])
df_results
```

```{python}
colunas = ['gunning_fog', 'polarity','subjectivity']

dados_treino['gunning_fog'] = dados_treino['context'].apply(textstat.gunning_fog)
dados_treino['polarity'] = dados_treino['context'].apply(lambda x: TextBlob(x).sentiment.polarity)
dados_treino['subjectivity'] = dados_treino['context'].apply(lambda x: TextBlob(x).sentiment.subjectivity)

dados_teste['gunning_fog'] = dados_teste['context'].apply(textstat.gunning_fog)
dados_teste['polarity'] = dados_teste['context'].apply(lambda x: TextBlob(x).sentiment.polarity)
dados_teste['subjectivity'] = dados_teste['context'].apply(lambda x: TextBlob(x).sentiment.subjectivity)
```

```{python}
model = SVR()
model.fit(dados_treino[colunas], dados_treino['storypoints'])
y_pred = model.predict(dados_teste[colunas])
mae_leg = mean_absolute_error(dados_teste['storypoints'], y_pred)
df_results = df_results.append({'modelo':'Legibility SVM', 'MAE Teste': mae_leg, 'color': 'orange'}, ignore_index=True)
df_results
```
O MAE do modelo preditivo legibility é menor do que o MAE, quando utilizamos a média dos Story Poits.

```{python}
vec = TfidfVectorizer(max_features=50)
tfidf_matrix_treino = vec.fit_transform(dados_treino['context'])
tfidf_matrix_teste = vec.transform(dados_teste['context'])
```

```{python}
model = SVR()
model.fit(tfidf_matrix_treino, dados_treino['storypoints'])
y_pred = model.predict(tfidf_matrix_teste)
mae_tfidf = mean_absolute_error(dados_teste['storypoints'], y_pred)
df_results = df_results.append({'modelo':'TF-IDF SVM', 'MAE Teste': mae_tfidf, 'color': 'green'}, ignore_index=True)
df_results
```
```{python}
plt.figure()
df_results = df_results.sort_values(by='MAE Teste')
plt.bar(df_results['modelo'], df_results['MAE Teste'], color=df_results['color'])
plt.title('Comparação do MAE entre os modelos')
plt.xlabel('Modelos')
plt.ylabel('MAE')
plt.show()
```
